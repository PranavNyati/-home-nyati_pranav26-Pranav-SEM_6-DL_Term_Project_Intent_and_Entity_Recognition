{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Libraries","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers\n!pip install -q deep-translator","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:12:05.890062Z","iopub.execute_input":"2023-11-11T09:12:05.890956Z","iopub.status.idle":"2023-11-11T09:12:32.584788Z","shell.execute_reply.started":"2023-11-11T09:12:05.890919Z","shell.execute_reply":"2023-11-11T09:12:32.583536Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import RobertaTokenizer, RobertaModel, AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nimport warnings\nfrom deep_translator import GoogleTranslator\nwarnings.filterwarnings(\"ignore\")\nRobertatokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nBioclinicaltokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:12:32.586931Z","iopub.execute_input":"2023-11-11T09:12:32.587293Z","iopub.status.idle":"2023-11-11T09:12:48.971691Z","shell.execute_reply.started":"2023-11-11T09:12:32.587261Z","shell.execute_reply":"2023-11-11T09:12:48.970696Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd6973c2f507454b8879ae61a1bb7336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fab244f4c134ef2b19a4e0fc1567981"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abf19cec338a4b8f8976f2eedad5e391"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1b8a98583664e9696c2d9c56ce94235"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da89c190e79346aba499e2bcd5000b5c"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Setting the path to files and model name","metadata":{}},{"cell_type":"code","source":"model_name = 'bioclinical' # can be 'bioclinical' for bioclinical_bert or 'roberta' for Roberta\ntrain_path = \"/kaggle/input/ihqid-webmd/IHQID-WebMD/train.csv\"\ntest_path = \"/kaggle/input/ihqid-webmd/IHQID-WebMD/test.csv\"\n\nMAX_LEN = 200\nTRAIN_BATCH_SIZE = 8\nVALID_BATCH_SIZE = 4\nEPOCHS = 10\nLEARNING_RATE = 1e-05","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:12:48.973212Z","iopub.execute_input":"2023-11-11T09:12:48.973853Z","iopub.status.idle":"2023-11-11T09:12:48.979417Z","shell.execute_reply.started":"2023-11-11T09:12:48.973818Z","shell.execute_reply":"2023-11-11T09:12:48.978303Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Loading and Preprocessing Data","metadata":{}},{"cell_type":"code","source":"def translate_to_english(text):\n    try:\n        translated_text_1 = GoogleTranslator(source='bn', target='hi').translate(text)\n        translated_text = GoogleTranslator(source='hi', target='en').translate(translated_text_1)\n        return translated_text\n    except Exception as e:\n        print(f\"Translation error: {e}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:36:38.596701Z","iopub.execute_input":"2023-11-11T09:36:38.597899Z","iopub.status.idle":"2023-11-11T09:36:38.604045Z","shell.execute_reply.started":"2023-11-11T09:36:38.597858Z","shell.execute_reply":"2023-11-11T09:36:38.602989Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:36:38.829531Z","iopub.execute_input":"2023-11-11T09:36:38.830371Z","iopub.status.idle":"2023-11-11T09:36:38.880039Z","shell.execute_reply.started":"2023-11-11T09:36:38.830337Z","shell.execute_reply":"2023-11-11T09:36:38.879160Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def one_hot_encode(row):\n    one_hot = [1 if cell else 0 for cell in row]\n    return one_hot\n\ntrain_df = train_df[['question_bengali', 'Manual_Intent']]\ntest_df = test_df[['question_bengali', 'Manual_Intent']]\n# Apply the translation function to the 'questions_hindi' column\ntrain_df['question_conv'] = train_df['question_bengali'].apply(translate_to_english)\ntest_df['question_conv'] = test_df['question_bengali'].apply(translate_to_english)\ntrain_eng = train_df[['question_conv', 'Manual_Intent']]\ntest_eng = test_df[['question_conv', 'Manual_Intent']]\n\nunique_values = train_eng['Manual_Intent'].unique()\n\n# Function to create the one-hot encoded list for each row\ndef one_hot_encode_category(row, unique_values):\n    one_hot = [1 if value == row['Manual_Intent'] else 0 for value in unique_values]\n    return one_hot\n\n# Apply the function to create the new one-hot encoded column\ntrain_eng['one_hot_encoded'] = train_eng.apply(one_hot_encode_category, args=(unique_values,), axis=1)\ntest_eng['one_hot_encoded'] = test_eng.apply(one_hot_encode_category, args=(unique_values,), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:36:39.134597Z","iopub.execute_input":"2023-11-11T09:36:39.134972Z","iopub.status.idle":"2023-11-11T09:40:04.261926Z","shell.execute_reply.started":"2023-11-11T09:36:39.134941Z","shell.execute_reply":"2023-11-11T09:40:04.260855Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_eng = train_eng[['question_conv', 'one_hot_encoded']]\ntest_eng = test_eng[['question_conv', 'one_hot_encoded']]\ntest_eng.columns = ['input', 'target']\ntrain_eng.columns = ['input', 'target']","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:04.264128Z","iopub.execute_input":"2023-11-11T09:40:04.264560Z","iopub.status.idle":"2023-11-11T09:40:04.273313Z","shell.execute_reply.started":"2023-11-11T09:40:04.264519Z","shell.execute_reply":"2023-11-11T09:40:04.272196Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_eng","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:04.274850Z","iopub.execute_input":"2023-11-11T09:40:04.275255Z","iopub.status.idle":"2023-11-11T09:40:04.301338Z","shell.execute_reply.started":"2023-11-11T09:40:04.275217Z","shell.execute_reply":"2023-11-11T09:40:04.300233Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                                 input        target\n0                     What is nystatin prescribed for?  [1, 0, 0, 0]\n1    Can showering after sex prevent me from gettin...  [0, 1, 0, 0]\n2                          Percocet causes weight gain  [1, 0, 0, 0]\n3    Can 2 or 2 1/2 glasses of wine a day cause hig...  [0, 0, 1, 0]\n4                Can too much buttermilk cause thrush?  [0, 0, 1, 0]\n..                                                 ...           ...\n715  Can an insurance company be required to cover ...  [0, 1, 0, 0]\n716       How can I use duct tape to get rid of warts?  [0, 0, 0, 1]\n717  Bell's Palsy What facial exercises can be done...  [0, 0, 0, 1]\n718                       Is prenatal ultrasound safe?  [0, 0, 0, 1]\n719  How can I reduce inguinal hernia symptoms unti...  [0, 0, 0, 1]\n\n[720 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is nystatin prescribed for?</td>\n      <td>[1, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Can showering after sex prevent me from gettin...</td>\n      <td>[0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Percocet causes weight gain</td>\n      <td>[1, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Can 2 or 2 1/2 glasses of wine a day cause hig...</td>\n      <td>[0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Can too much buttermilk cause thrush?</td>\n      <td>[0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>Can an insurance company be required to cover ...</td>\n      <td>[0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>How can I use duct tape to get rid of warts?</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>Bell's Palsy What facial exercises can be done...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>718</th>\n      <td>Is prenatal ultrasound safe?</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>719</th>\n      <td>How can I reduce inguinal hernia symptoms unti...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n  </tbody>\n</table>\n<p>720 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.input = dataframe.input\n        self.targets = self.data.target\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.input)\n\n    def __getitem__(self, index):\n        text = str(self.input[index])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:04.304127Z","iopub.execute_input":"2023-11-11T09:40:04.304583Z","iopub.status.idle":"2023-11-11T09:40:04.314752Z","shell.execute_reply.started":"2023-11-11T09:40:04.304543Z","shell.execute_reply":"2023-11-11T09:40:04.313747Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_eng\ntest_dataset = test_eng\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\nif(model_name == 'roberta'):\n    tokenizer = Robertatokenizer\nelif(model_name == 'bioclinical'):\n    tokenizer = Bioclinicaltokenizer\nelse:\n    print(\"Doesnt exist model name, please enter correctly\")\n    \ntraining_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\ntesting_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:04.315882Z","iopub.execute_input":"2023-11-11T09:40:04.316216Z","iopub.status.idle":"2023-11-11T09:40:04.334381Z","shell.execute_reply.started":"2023-11-11T09:40:04.316188Z","shell.execute_reply":"2023-11-11T09:40:04.333316Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"TRAIN Dataset: (720, 2)\nTEST Dataset: (241, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,'shuffle': True,'num_workers': 0}\ntest_params = {'batch_size': VALID_BATCH_SIZE,'shuffle': True,'num_workers': 0}\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:04.335766Z","iopub.execute_input":"2023-11-11T09:40:04.336527Z","iopub.status.idle":"2023-11-11T09:40:04.348160Z","shell.execute_reply.started":"2023-11-11T09:40:04.336487Z","shell.execute_reply":"2023-11-11T09:40:04.347293Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Building Customized classes for model for end to end finetuning","metadata":{}},{"cell_type":"code","source":" class RobertaClass(torch.nn.Module):\n    def __init__(self):\n        super(RobertaClass, self).__init__()\n        self.l1 = RobertaModel.from_pretrained('roberta-base')\n        self.l2 = torch.nn.Linear(768, 4)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict = False)\n        output = self.l2(output_1)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:04.349439Z","iopub.execute_input":"2023-11-11T09:40:04.349788Z","iopub.status.idle":"2023-11-11T09:40:04.360065Z","shell.execute_reply.started":"2023-11-11T09:40:04.349761Z","shell.execute_reply":"2023-11-11T09:40:04.359004Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":" class BioclinicalClass(torch.nn.Module):\n    def __init__(self):\n        super(BioclinicalClass, self).__init__()\n        self.l1 = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n        self.l2 = torch.nn.Linear(768, 4)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict = False)\n        output = self.l2(output_1)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:04.361237Z","iopub.execute_input":"2023-11-11T09:40:04.361585Z","iopub.status.idle":"2023-11-11T09:40:04.376179Z","shell.execute_reply.started":"2023-11-11T09:40:04.361556Z","shell.execute_reply":"2023-11-11T09:40:04.375347Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Initializing the model and setting the loss function and optimizer","metadata":{}},{"cell_type":"code","source":"if(model_name == 'roberta'):\n    model = RobertaClass()\nelif (model_name == 'bioclinical'):\n    model = BioclinicalClass()\n    \nmodel.to(device)\ndef loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:04.377566Z","iopub.execute_input":"2023-11-11T09:40:04.377947Z","iopub.status.idle":"2023-11-11T09:40:06.154265Z","shell.execute_reply.started":"2023-11-11T09:40:04.377908Z","shell.execute_reply":"2023-11-11T09:40:06.153350Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train(epoch):\n    model.train()\n    for _,data in enumerate(training_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n        outputs = model(ids, mask, token_type_ids)\n        optimizer.zero_grad()\n        loss = loss_fn(outputs, targets.float())\n        if _%5000==0:\n            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:06.157463Z","iopub.execute_input":"2023-11-11T09:40:06.157806Z","iopub.status.idle":"2023-11-11T09:40:06.165835Z","shell.execute_reply.started":"2023-11-11T09:40:06.157777Z","shell.execute_reply":"2023-11-11T09:40:06.164789Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    train(epoch)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:40:06.166995Z","iopub.execute_input":"2023-11-11T09:40:06.167290Z","iopub.status.idle":"2023-11-11T09:42:35.322242Z","shell.execute_reply.started":"2023-11-11T09:40:06.167263Z","shell.execute_reply":"2023-11-11T09:42:35.320992Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch: 0, Loss:  0.8055540323257446\nEpoch: 1, Loss:  0.5429575443267822\nEpoch: 2, Loss:  0.39278924465179443\nEpoch: 3, Loss:  0.24717780947685242\nEpoch: 4, Loss:  0.2451520413160324\nEpoch: 5, Loss:  0.17690199613571167\nEpoch: 6, Loss:  0.050609491765499115\nEpoch: 7, Loss:  0.0518803671002388\nEpoch: 8, Loss:  0.04026336967945099\nEpoch: 9, Loss:  0.022489354014396667\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"def test_validation():\n    model.eval()\n    fin_targets=[]\n    fin_outputs=[]\n    with torch.no_grad():\n        for _, data in enumerate(testing_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, token_type_ids)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:42:35.324139Z","iopub.execute_input":"2023-11-11T09:42:35.324481Z","iopub.status.idle":"2023-11-11T09:42:35.332704Z","shell.execute_reply.started":"2023-11-11T09:42:35.324430Z","shell.execute_reply":"2023-11-11T09:42:35.331488Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"outputs, targets = test_validation()\noutputs = np.array(outputs) >= 0.5\nf1_score_macro = metrics.f1_score(targets, outputs, average='macro')\nclassification_report = metrics.classification_report(targets, outputs)\nconfusion_matrix = metrics.multilabel_confusion_matrix(targets, outputs)\nprint(f\"Test F1 Score (Macro) = {f1_score_macro}\")\nprint(\"Test classification report = \\n\")\nprint(classification_report)\nprint(\"Test confusion matrix = \\n\")\nprint(confusion_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:42:35.334181Z","iopub.execute_input":"2023-11-11T09:42:35.334865Z","iopub.status.idle":"2023-11-11T09:42:37.347825Z","shell.execute_reply.started":"2023-11-11T09:42:35.334814Z","shell.execute_reply":"2023-11-11T09:42:37.346788Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Test F1 Score (Macro) = 0.7533757379345615\nTest classification report = \n\n              precision    recall  f1-score   support\n\n           0       0.86      0.79      0.82        53\n           1       0.75      0.77      0.76        73\n           2       0.84      0.74      0.78        76\n           3       0.63      0.67      0.65        39\n\n   micro avg       0.78      0.75      0.76       241\n   macro avg       0.77      0.74      0.75       241\nweighted avg       0.78      0.75      0.76       241\n samples avg       0.74      0.75      0.75       241\n\nTest confusion matrix = \n\n[[[181   7]\n  [ 11  42]]\n\n [[149  19]\n  [ 17  56]]\n\n [[154  11]\n  [ 20  56]]\n\n [[187  15]\n  [ 13  26]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}